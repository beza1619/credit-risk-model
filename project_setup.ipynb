{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6035cf45-9754-4968-8051-60d98bee55bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project structure...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"Creating project structure...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb09d2d2-bb8f-4c91-9eb4-d0f068a7ce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: .github/workflows\n",
      "Created: data/raw\n",
      "Created: data/processed\n",
      "Created: notebooks\n",
      "Created: src\n",
      "Created: src/api\n",
      "Created: tests\n"
     ]
    }
   ],
   "source": [
    "# List of directories to create\n",
    "directories = [\n",
    "    '.github/workflows',\n",
    "    'data/raw',\n",
    "    'data/processed',\n",
    "    'notebooks',\n",
    "    'src',\n",
    "    'src/api',\n",
    "    'tests'\n",
    "]\n",
    "\n",
    "for dir_path in directories:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"Created: {dir_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621134d2-0e60-413b-8c07-d81539056eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: .github/workflows/ci.yml\n",
      "Created: notebooks/eda.ipynb\n",
      "Created: src/__init__.py\n",
      "Created: src/data_processing.py\n",
      "Created: src/train.py\n",
      "Created: src/predict.py\n",
      "Created: src/api/main.py\n",
      "Created: src/api/pydantic_models.py\n",
      "Created: tests/test_data_processing.py\n",
      "Created: Dockerfile\n",
      "Created: docker-compose.yml\n",
      "Created: requirements.txt\n",
      "Created: .gitignore\n",
      "Created: README.md\n"
     ]
    }
   ],
   "source": [
    "# List of files to create\n",
    "files_to_create = [\n",
    "    ('.github/workflows/ci.yml', ''),\n",
    "    ('notebooks/eda.ipynb', ''),\n",
    "    ('src/__init__.py', ''),\n",
    "    ('src/data_processing.py', ''),\n",
    "    ('src/train.py', ''),\n",
    "    ('src/predict.py', ''),\n",
    "    ('src/api/main.py', ''),\n",
    "    ('src/api/pydantic_models.py', ''),\n",
    "    ('tests/test_data_processing.py', ''),\n",
    "    ('Dockerfile', ''),\n",
    "    ('docker-compose.yml', ''),\n",
    "    ('requirements.txt', ''),\n",
    "    ('.gitignore', ''),\n",
    "    ('README.md', '')\n",
    "]\n",
    "\n",
    "for file_path, content in files_to_create:\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    print(f\"Created: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16328ba-7e7f-4b8c-a7e8-326962a98b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".gitignore created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create .gitignore content\n",
    "gitignore_content = \"\"\"# Data\n",
    "data/\n",
    "*.csv\n",
    "*.parquet\n",
    "*.feather\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.py[cod]\n",
    "*$py.class\n",
    "*.so\n",
    ".Python\n",
    "env/\n",
    "venv/\n",
    ".venv/\n",
    "ENV/\n",
    "env.bak/\n",
    "venv.bak/\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "*.swp\n",
    "*.swo\n",
    "\n",
    "# Jupyter\n",
    ".ipynb_checkpoints/\n",
    "\n",
    "# MLFlow\n",
    "mlruns/\n",
    "mlartifacts/\n",
    "\n",
    "# OS\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "\n",
    "# Logs\n",
    "*.log\n",
    "\"\"\"\n",
    "\n",
    "# Write to .gitignore\n",
    "with open('.gitignore', 'w', encoding='utf-8') as f:\n",
    "    f.write(gitignore_content)\n",
    "\n",
    "print(\".gitignore created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923f7969-1fb3-4b76-b47d-c5afa9cbbb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements.txt created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create requirements.txt content\n",
    "requirements_content = \"\"\"# Core\n",
    "pandas==2.0.3\n",
    "numpy==1.24.3\n",
    "scikit-learn==1.3.0\n",
    "matplotlib==3.7.2\n",
    "seaborn==0.12.2\n",
    "jupyter==1.0.0\n",
    "notebook==6.5.4\n",
    "\n",
    "# Feature Engineering\n",
    "category-encoders==2.6.3\n",
    "xverse==0.2.0\n",
    "\n",
    "# ML & MLOps\n",
    "mlflow==2.8.1\n",
    "xgboost==1.7.6\n",
    "lightgbm==4.1.0\n",
    "\n",
    "# API & Deployment\n",
    "fastapi==0.104.1\n",
    "uvicorn[standard]==0.24.0\n",
    "pydantic==2.5.0\n",
    "\n",
    "# Testing & Quality\n",
    "pytest==7.4.3\n",
    "black==23.11.0\n",
    "flake8==6.1.0\n",
    "\n",
    "# Data Processing\n",
    "pyarrow==14.0.1\n",
    "\"\"\"\n",
    "\n",
    "# Write to requirements.txt\n",
    "with open('requirements.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(requirements_content)\n",
    "\n",
    "print(\"requirements.txt created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d4cc1c-b442-4a6b-90d0-70d6eb2cf2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create README.md content\n",
    "readme_content = \"\"\"# Credit Risk Probability Model for Alternative Data\n",
    "\n",
    "## Project Overview\n",
    "This project develops a credit risk scoring model for Bati Bank's buy-now-pay-later service using e-commerce transaction data. The model transforms behavioral data into predictive risk signals to assess customer creditworthiness.\n",
    "\n",
    "## Credit Scoring Business Understanding\n",
    "\n",
    "### 1. Basel II Accord and Model Interpretability\n",
    "The Basel II Capital Accord emphasizes rigorous risk measurement and adequate capital allocation based on credit risk exposure. This influences our model development in three key ways:\n",
    "\n",
    "- **Regulatory Compliance**: Banks must demonstrate that their risk models are robust, validated, and conceptually sound. Our model needs clear documentation of methodology and assumptions.\n",
    "\n",
    "- **Capital Requirements**: Accurate risk probability estimates directly impact the amount of capital Bati Bank must hold. Underestimation could lead to insufficient capital buffers.\n",
    "\n",
    "- **Explainability**: Regulators require models to be interpretable for validation purposes. We must be able to explain why a customer receives a particular risk score, which is crucial for compliance and customer communication.\n",
    "\n",
    "### 2. Proxy Variable Necessity and Risks\n",
    "Since we lack direct loan performance data, creating a proxy variable is essential:\n",
    "\n",
    "**Why necessary:**\n",
    "- No historical loan default data exists for e-commerce customers\n",
    "- RFM (Recency, Frequency, Monetary) patterns serve as behavioral proxies for creditworthiness\n",
    "- Disengaged customers (low frequency, low spending) may correlate with higher default risk\n",
    "\n",
    "**Potential business risks:**\n",
    "- **Misclassification Risk**: Customers labeled as high-risk based on shopping behavior may actually be creditworthy\n",
    "- **Opportunity Cost**: Overly conservative models could reject profitable customers\n",
    "- **Discrimination Risk**: Behavioral proxies might unintentionally exclude certain customer segments\n",
    "- **Validation Challenges**: Proxy-based models are harder to validate against actual loan performance\n",
    "\n",
    "### 3. Model Selection Trade-offs in Financial Context\n",
    "\n",
    "**Simple, Interpretable Models (Logistic Regression with WoE):**\n",
    "- **Advantages**: \n",
    "  - Easily explainable to regulators and business stakeholders\n",
    "  - Linear relationships make risk factor contributions transparent\n",
    "  - Well-established in credit scoring with proven regulatory acceptance\n",
    "  - Lower computational requirements\n",
    "\n",
    "- **Disadvantages**:\n",
    "  - May capture fewer complex, non-linear patterns\n",
    "  - Lower predictive power if relationships are non-linear\n",
    "  - Requires careful feature engineering and transformation\n",
    "\n",
    "**Complex, High-Performance Models (Gradient Boosting):**\n",
    "- **Advantages**:\n",
    "  - Higher predictive accuracy through complex pattern recognition\n",
    "  - Automatic feature interaction detection\n",
    "  - Better handling of non-linear relationships\n",
    "\n",
    "- **Disadvantages**:\n",
    "  - \"Black box\" nature challenges regulatory compliance\n",
    "  - Harder to explain individual predictions\n",
    "  - Potential overfitting without careful regularization\n",
    "  - Higher computational costs and maintenance complexity\n",
    "\n",
    "**Recommended Approach**: Start with interpretable models for regulatory acceptance, then explore ensemble methods if interpretability requirements allow and performance gains justify the complexity. Consider using SHAP values for model explainability with complex models.\n",
    "\n",
    "## Project Structure\n",
    "[Project structure as defined in requirements]\n",
    "\n",
    "## Setup Instructions\n",
    "1. Clone the repository\n",
    "2. Install requirements: `pip install -r requirements.txt`\n",
    "3. Download data from Kaggle to `data/raw/`\n",
    "4. Run EDA: `jupyter notebook notebooks/eda.ipynb`\n",
    "5. Train model: `python src/train.py`\n",
    "\"\"\"\n",
    "\n",
    "# Write to README.md\n",
    "with open('README.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"README.md created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282e9568-392f-4289-b4b6-937fe896b7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current project structure:\n",
      "./\n",
      "    .gitignore\n",
      "    check_notebook.py\n",
      "    docker-compose.yml\n",
      "    Dockerfile\n",
      "    fix_notebook.py\n",
      "    project_setup.ipynb\n",
      "    README.md\n",
      "    requirements.txt\n",
      "    .git/\n",
      "        COMMIT_EDITMSG\n",
      "        config\n",
      "        description\n",
      "        HEAD\n",
      "        index\n",
      "        hooks/\n",
      "            applypatch-msg.sample\n",
      "            commit-msg.sample\n",
      "            fsmonitor-watchman.sample\n",
      "            post-update.sample\n",
      "            pre-applypatch.sample\n",
      "            pre-commit.sample\n",
      "            pre-merge-commit.sample\n",
      "            pre-push.sample\n",
      "            pre-rebase.sample\n",
      "            pre-receive.sample\n",
      "            prepare-commit-msg.sample\n",
      "            push-to-checkout.sample\n",
      "            sendemail-validate.sample\n",
      "            update.sample\n",
      "        info/\n",
      "            exclude\n",
      "        logs/\n",
      "            HEAD\n",
      "            refs/\n",
      "                heads/\n",
      "                    main\n",
      "                remotes/\n",
      "                    origin/\n",
      "                        main\n",
      "        objects/\n",
      "            00/\n",
      "                fb817518a3fdc05d2a9ceac9d749d7901a7007\n",
      "            06/\n",
      "                fe68665b1ddfd6e3b0a9b81f8cde5da0b681fd\n",
      "            18/\n",
      "                fc3eade031098104e1a250bec58f8332dddd18\n",
      "            1a/\n",
      "                3789752b9b389bf5cbbf7e0f0e1f070adc462c\n",
      "            1d/\n",
      "                28d7f71880f5ffd6a3c44416b388177e677fbc\n",
      "                9457f00a6ec5893222896b0b1378cac12eca3b\n",
      "            23/\n",
      "                4ae01e01a72ac4a714c5349e43cc2db3417bc2\n",
      "            34/\n",
      "                cb5b387ef68848183617aa4539693d35bb852a\n",
      "            36/\n",
      "                3fcab7ed6e9634e198cf5555ceb88932c9a245\n",
      "            37/\n",
      "                dd703a835e4090e2525f8dbb7a376a2887171f\n",
      "            52/\n",
      "                e31359a834627044df847a9cc90b3d0f2a9ed9\n",
      "            55/\n",
      "                a788b266f9591b048f9b2d4f49fdf0346873a8\n",
      "            5a/\n",
      "                723c042756b9dd9c932e95ace9f89de248d6d0\n",
      "            5c/\n",
      "                4eb7cc9688bd73a9b6273a34b6e24866682282\n",
      "            6b/\n",
      "                d6a4c0dac8b9040604aaf140cccc69a39ab7ee\n",
      "            72/\n",
      "                1309ca5f13db399f615633350b1dfd8c834bf1\n",
      "            74/\n",
      "                755c0dfebc6888199754f418926ac5b1f34b16\n",
      "            7a/\n",
      "                7b9fc36396668cc8cf6f0cc20def3bf03c6c9d\n",
      "                8b757ec7d19b6ce5d21941efc50df950f259ee\n",
      "            7b/\n",
      "                2d3eb7360ecfeea55b305836fa5f1ead459001\n",
      "                7e3661d9d24107684ba2b639a8770a34648310\n",
      "            82/\n",
      "                08028a4f2a3c07b9b6cef182305e4f37ce79c6\n",
      "                996cee3670f47ee132cb111a51eaabe12b54b3\n",
      "            9b/\n",
      "                1d056e4415c509ed57870e6ce8d1252631377f\n",
      "            b0/\n",
      "                88ea3dfd7da0eaaadda71068865654031abf1b\n",
      "            c1/\n",
      "                f47812782dbf857396435ba64a136f481ccfe9\n",
      "            c6/\n",
      "                909987e255fbdaf1bdcc345ed7a5b9d9cf6449\n",
      "            d0/\n",
      "                685b3ad2490c667b9b33bd7d55a09b0bf8acf8\n",
      "                d20b2b9aa34b9e8dd8f54c17e71df91e30ec0b\n",
      "            d2/\n",
      "                a821f8743b2a7ee63e215bfb4596d6aba6242f\n",
      "            e6/\n",
      "                9de29bb2d1d6434b8b29ae775ad8c2e48c5391\n",
      "                ef1e668c410d5d412f6381a004231225e55f55\n",
      "            eb/\n",
      "                5565f0954c9c8094dd370da1f8272c72a242f0\n",
      "            f4/\n",
      "                192478f3ed3085615ff9eb322d1d4b9f352234\n",
      "            f6/\n",
      "                66bf4ae41c99ad81f18fc3607d646708025274\n",
      "            fb/\n",
      "                4ff4c5a94941d4729b37bd0b470853bd81cf62\n",
      "            fd/\n",
      "                c162ddd72a6e51e078dae74230a3349855eaca\n",
      "            info/\n",
      "            pack/\n",
      "        refs/\n",
      "            heads/\n",
      "                main\n",
      "            remotes/\n",
      "                origin/\n",
      "                    main\n",
      "            tags/\n",
      "    .github/\n",
      "        workflows/\n",
      "            ci.yml\n",
      "    .ipynb_checkpoints/\n",
      "        project_setup-checkpoint.ipynb\n",
      "    data/\n",
      "        processed/\n",
      "            features_data.csv\n",
      "            high_risk_labels.csv\n",
      "        raw/\n",
      "            data.csv\n",
      "            Xente_Variable_Definitions.csv\n",
      "    notebooks/\n",
      "        eda.ipynb\n",
      "        task4_rfm_clustering.ipynb\n",
      "        .ipynb_checkpoints/\n",
      "            eda-checkpoint.ipynb\n",
      "            task4_rfm_clustering-checkpoint.ipynb\n",
      "    src/\n",
      "        data_processing.py\n",
      "        predict.py\n",
      "        train.py\n",
      "        __init__.py\n",
      "        api/\n",
      "            main.py\n",
      "            pydantic_models.py\n",
      "    tests/\n",
      "        test_data_processing.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f'{subindent}{file}')\n",
    "\n",
    "print(\"Current project structure:\")\n",
    "list_files('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a5b99-b2a5-4a23-9216-5466c6da93c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
