{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c80e91f-2ba8-466b-b231-a31971da44a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: LOAD DATA ===\n",
      "Loading: ../data/raw/data.xls\n",
      "✗ ERROR loading file: [Errno 2] No such file or directory: '../data/raw/data.xls'\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - Exploratory Data Analysis (EDA)\n",
    "# Xente Credit Risk Model - Initial Data Inspection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== STEP 1: LOAD DATA ===\")\n",
    "\n",
    "# Try to load the Excel file\n",
    "file_path = \"../data/raw/data.xls\"\n",
    "print(f\"Loading: {file_path}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(file_path)\n",
    "    print(\"✓ File loaded successfully!\")\n",
    "    \n",
    "    print(f\"\\n=== BASIC INFO ===\")\n",
    "    print(f\"Shape: {df.shape} (rows, columns)\")\n",
    "    print(f\"\\nColumn names:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i}. '{col}'\")\n",
    "    \n",
    "    print(f\"\\n=== FIRST 2 ROWS ===\")\n",
    "    print(df.head(2))\n",
    "    \n",
    "    print(f\"\\n=== DATA TYPES ===\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ ERROR loading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7302cd1-4cb1-4d8a-bb57-6cdee00ef9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHECK WHAT FILES EXIST ===\n",
      "Checking: C:\\Users\\b\\Desktop\\credit-risk-model\\notebooks\\data\\raw\n",
      "✗ Error: [WinError 3] The system cannot find the path specified: './data/raw/'\n",
      "\n",
      "Trying to list from project root:\n",
      "['.ipynb_checkpoints', 'eda.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== CHECK WHAT FILES EXIST ===\")\n",
    "import os\n",
    "\n",
    "# List files in data/raw\n",
    "data_path = \"./data/raw/\"\n",
    "print(f\"Checking: {os.path.abspath(data_path)}\")\n",
    "\n",
    "try:\n",
    "    files = os.listdir(data_path)\n",
    "    print(f\"✓ Found {len(files)} file(s):\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")\n",
    "    print(\"\\nTrying to list from project root:\")\n",
    "    print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff51b0f-b2a0-400c-aee9-50745695547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHECK PROJECT STRUCTURE ===\n",
      "Now in: C:\\Users\\b\\Desktop\\credit-risk-model\n",
      "\n",
      "Folders and files here:\n",
      "  - .github\n",
      "  - .gitignore\n",
      "  - data\n",
      "  - notebooks\n",
      "  - README.md\n",
      "  - requirements.txt\n",
      "  - src\n",
      "  - tests\n",
      "\n",
      "=== CHECK FOR DATA FOLDER ===\n",
      "✓ 'data' folder exists\n",
      "Contents of data/:\n",
      "['processed', 'raw']\n",
      "\n",
      "Contents of data/raw:\n",
      "['data.csv', 'Xente_Variable_Definitions.csv']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== CHECK PROJECT STRUCTURE ===\")\n",
    "import os\n",
    "\n",
    "# Go up one level from notebooks\n",
    "os.chdir(\"..\")  # Go to credit-risk-model folder\n",
    "print(f\"Now in: {os.getcwd()}\")\n",
    "\n",
    "print(\"\\nFolders and files here:\")\n",
    "for item in os.listdir(\".\"):\n",
    "    print(f\"  - {item}\")\n",
    "\n",
    "# Check if data folder exists\n",
    "print(\"\\n=== CHECK FOR DATA FOLDER ===\")\n",
    "if os.path.exists(\"data\"):\n",
    "    print(\"✓ 'data' folder exists\")\n",
    "    print(\"Contents of data/:\")\n",
    "    print(os.listdir(\"data\"))\n",
    "    \n",
    "    if os.path.exists(\"data/raw\"):\n",
    "        print(\"\\nContents of data/raw:\")\n",
    "        print(os.listdir(\"data/raw\"))\n",
    "    else:\n",
    "        print(\"✗ No 'data/raw' folder\")\n",
    "else:\n",
    "    print(\"✗ No 'data' folder at all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66535c96-db9f-420d-95e5-47b4eba0e689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOAD THE CORRECT DATA FILE ===\n",
      "✓ File loaded: data.csv\n",
      "Shape: (95662, 16) rows, 16 columns\n",
      "\n",
      "=== COLUMN NAMES ===\n",
      " 1. TransactionId\n",
      " 2. BatchId\n",
      " 3. AccountId\n",
      " 4. SubscriptionId\n",
      " 5. CustomerId\n",
      " 6. CurrencyCode\n",
      " 7. CountryCode\n",
      " 8. ProviderId\n",
      " 9. ProductId\n",
      "10. ProductCategory\n",
      "11. ChannelId\n",
      "12. Amount\n",
      "13. Value\n",
      "14. TransactionStartTime\n",
      "15. PricingStrategy\n",
      "16. FraudResult\n",
      "\n",
      "=== FIRST 3 ROWS ===\n",
      "         TransactionId        BatchId       AccountId       SubscriptionId  \\\n",
      "0  TransactionId_76871  BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
      "1  TransactionId_73770  BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
      "2  TransactionId_26203  BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
      "\n",
      "        CustomerId CurrencyCode  CountryCode    ProviderId     ProductId  \\\n",
      "0  CustomerId_4406          UGX          256  ProviderId_6  ProductId_10   \n",
      "1  CustomerId_4406          UGX          256  ProviderId_4   ProductId_6   \n",
      "2  CustomerId_4683          UGX          256  ProviderId_6   ProductId_1   \n",
      "\n",
      "      ProductCategory    ChannelId  Amount  Value  TransactionStartTime  \\\n",
      "0             airtime  ChannelId_3  1000.0   1000  2018-11-15T02:18:49Z   \n",
      "1  financial_services  ChannelId_2   -20.0     20  2018-11-15T02:19:08Z   \n",
      "2             airtime  ChannelId_3   500.0    500  2018-11-15T02:44:21Z   \n",
      "\n",
      "   PricingStrategy  FraudResult  \n",
      "0                2            0  \n",
      "1                2            0  \n",
      "2                2            0  \n",
      "\n",
      "=== BASIC INFO ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95662 entries, 0 to 95661\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   TransactionId         95662 non-null  object \n",
      " 1   BatchId               95662 non-null  object \n",
      " 2   AccountId             95662 non-null  object \n",
      " 3   SubscriptionId        95662 non-null  object \n",
      " 4   CustomerId            95662 non-null  object \n",
      " 5   CurrencyCode          95662 non-null  object \n",
      " 6   CountryCode           95662 non-null  int64  \n",
      " 7   ProviderId            95662 non-null  object \n",
      " 8   ProductId             95662 non-null  object \n",
      " 9   ProductCategory       95662 non-null  object \n",
      " 10  ChannelId             95662 non-null  object \n",
      " 11  Amount                95662 non-null  float64\n",
      " 12  Value                 95662 non-null  int64  \n",
      " 13  TransactionStartTime  95662 non-null  object \n",
      " 14  PricingStrategy       95662 non-null  int64  \n",
      " 15  FraudResult           95662 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(11)\n",
      "memory usage: 11.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"=== LOAD THE CORRECT DATA FILE ===\")\n",
    "\n",
    "# Load the CSV file (not Excel)\n",
    "df = pd.read_csv(\"./data/raw/data.csv\")\n",
    "\n",
    "print(f\"✓ File loaded: data.csv\")\n",
    "print(f\"Shape: {df.shape} rows, {df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n=== COLUMN NAMES ===\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2}. {col}\")\n",
    "\n",
    "print(\"\\n=== FIRST 3 ROWS ===\")\n",
    "print(df.head(3))\n",
    "\n",
    "print(\"\\n=== BASIC INFO ===\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87778275-66d6-4fc6-9b2c-e9a20d04d68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 2: DATA CLEANING ===\n",
      "Created TransactionId_numeric with 95662 unique values\n",
      "Created BatchId_numeric with 94809 unique values\n",
      "Created AccountId_numeric with 3633 unique values\n",
      "Created SubscriptionId_numeric with 3627 unique values\n",
      "Created CustomerId_numeric with 3742 unique values\n",
      "Created ProviderId_numeric with 6 unique values\n",
      "Created ProductId_numeric with 23 unique values\n",
      "Created ChannelId_numeric with 4 unique values\n",
      "\n",
      "=== BASIC STATISTICS ===\n",
      "\n",
      "1. Numeric columns summary:\n",
      "             Amount         Value  CountryCode  PricingStrategy   FraudResult\n",
      "count  9.566200e+04  9.566200e+04      95662.0     95662.000000  95662.000000\n",
      "mean   6.717846e+03  9.900584e+03        256.0         2.255974      0.002018\n",
      "std    1.233068e+05  1.231221e+05          0.0         0.732924      0.044872\n",
      "min   -1.000000e+06  2.000000e+00        256.0         0.000000      0.000000\n",
      "25%   -5.000000e+01  2.750000e+02        256.0         2.000000      0.000000\n",
      "50%    1.000000e+03  1.000000e+03        256.0         2.000000      0.000000\n",
      "75%    2.800000e+03  5.000000e+03        256.0         2.000000      0.000000\n",
      "max    9.880000e+06  9.880000e+06        256.0         4.000000      1.000000\n",
      "\n",
      "2. Categorical columns unique values:\n",
      "\n",
      "CurrencyCode:\n",
      "CurrencyCode\n",
      "UGX    95662\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ProductCategory:\n",
      "ProductCategory\n",
      "financial_services    45405\n",
      "airtime               45027\n",
      "utility_bill           1920\n",
      "data_bundles           1613\n",
      "tv                     1279\n",
      "Name: count, dtype: int64\n",
      "\n",
      "FraudResult:\n",
      "FraudResult\n",
      "0    95469\n",
      "1      193\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 2: DATA CLEANING ===\")\n",
    "\n",
    "# Extract numeric IDs from string columns (e.g., 'AccountId_3957' -> 3957)\n",
    "id_columns = ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', \n",
    "              'CustomerId', 'ProviderId', 'ProductId', 'ChannelId']\n",
    "\n",
    "for col in id_columns:\n",
    "    if col in df.columns:\n",
    "        # Extract numbers after underscore\n",
    "        df[f'{col}_numeric'] = df[col].str.extract(r'(\\d+)$').astype(float)\n",
    "        print(f\"Created {col}_numeric with {df[f'{col}_numeric'].nunique()} unique values\")\n",
    "\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "print(\"\\n1. Numeric columns summary:\")\n",
    "print(df[['Amount', 'Value', 'CountryCode', 'PricingStrategy', 'FraudResult']].describe())\n",
    "\n",
    "print(\"\\n2. Categorical columns unique values:\")\n",
    "cat_cols = ['CurrencyCode', 'ProductCategory', 'FraudResult']\n",
    "for col in cat_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a7a2ab-fb54-4d4e-8510-2d5a3be7e6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 3: TIME ANALYSIS ===\n",
      "Time range: 2018-11-15 02:18:49+00:00 to 2019-02-13 10:01:28+00:00\n",
      "\n",
      "Transactions by hour:\n",
      "TransactionHour\n",
      "0     168\n",
      "1     176\n",
      "2     289\n",
      "3     714\n",
      "4    2329\n",
      "5    4161\n",
      "6    5325\n",
      "7    5723\n",
      "8    5639\n",
      "9    5443\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Transactions by month:\n",
      "TransactionMonth\n",
      "1     31783\n",
      "2     15772\n",
      "11    12472\n",
      "12    35635\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 3: TIME ANALYSIS ===\")\n",
    "\n",
    "# Convert to datetime\n",
    "df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])\n",
    "df['TransactionHour'] = df['TransactionStartTime'].dt.hour\n",
    "df['TransactionDay'] = df['TransactionStartTime'].dt.day\n",
    "df['TransactionMonth'] = df['TransactionStartTime'].dt.month\n",
    "df['TransactionYear'] = df['TransactionStartTime'].dt.year\n",
    "\n",
    "print(f\"Time range: {df['TransactionStartTime'].min()} to {df['TransactionStartTime'].max()}\")\n",
    "\n",
    "print(\"\\nTransactions by hour:\")\n",
    "print(df['TransactionHour'].value_counts().sort_index().head(10))\n",
    "\n",
    "print(\"\\nTransactions by month:\")\n",
    "print(df['TransactionMonth'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e5325f-6a27-480a-a837-af3fa145cb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 4: CUSTOMER BEHAVIOR ANALYSIS ===\n",
      "Number of unique customers: 3633\n",
      "\n",
      "Customer transaction statistics:\n",
      "       TransactionCount   TotalAmount     AvgAmount     StdAmount\n",
      "count       3633.000000  3.633000e+03  3.633000e+03  2.821000e+03\n",
      "mean          26.331407  1.768903e+05  1.973079e+04  1.642986e+04\n",
      "std          520.214361  2.879371e+06  1.695768e+05  1.142598e+05\n",
      "min            1.000000 -1.125619e+08 -1.571429e+05  0.000000e+00\n",
      "25%            2.000000  5.500000e+03  1.634940e+03  9.617700e+02\n",
      "50%            4.000000  2.600000e+04  5.000000e+03  2.828430e+03\n",
      "75%           14.000000  9.290500e+04  9.525310e+03  5.111930e+03\n",
      "max        30893.000000  8.346600e+07  8.601821e+06  3.309916e+06\n",
      "\n",
      "=== TRANSACTION DISTRIBUTION ===\n",
      "Top 5 customers by transaction count:\n",
      "                   TransactionCount  TotalAmount\n",
      "AccountId_numeric                               \n",
      "4841.0                        30893  -27750277.5\n",
      "4249.0                         4457 -112561886.0\n",
      "4840.0                         1738   -1738000.0\n",
      "3206.0                         1105    2677500.0\n",
      "318.0                          1070    3756973.0\n",
      "\n",
      "Bottom 5 customers by transaction count:\n",
      "                   TransactionCount  TotalAmount\n",
      "AccountId_numeric                               \n",
      "3.0                               1       5000.0\n",
      "4.0                               1      62000.0\n",
      "6.0                               1     200000.0\n",
      "7.0                               1        500.0\n",
      "9.0                               1       1000.0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 4: CUSTOMER BEHAVIOR ANALYSIS ===\")\n",
    "\n",
    "# Group by customer to understand behavior patterns\n",
    "customer_stats = df.groupby('AccountId_numeric').agg({\n",
    "    'TransactionId': 'count',  # Frequency\n",
    "    'Amount': ['sum', 'mean', 'std'],  # Monetary metrics\n",
    "    'TransactionStartTime': 'max'  # For recency\n",
    "}).round(2)\n",
    "\n",
    "customer_stats.columns = ['TransactionCount', 'TotalAmount', 'AvgAmount', 'StdAmount', 'LastTransaction']\n",
    "\n",
    "print(f\"Number of unique customers: {len(customer_stats)}\")\n",
    "print(f\"\\nCustomer transaction statistics:\")\n",
    "print(customer_stats.describe())\n",
    "\n",
    "# Check transaction distribution\n",
    "print(\"\\n=== TRANSACTION DISTRIBUTION ===\")\n",
    "print(\"Top 5 customers by transaction count:\")\n",
    "print(customer_stats.nlargest(5, 'TransactionCount')[['TransactionCount', 'TotalAmount']])\n",
    "\n",
    "print(\"\\nBottom 5 customers by transaction count:\")\n",
    "print(customer_stats.nsmallest(5, 'TransactionCount')[['TransactionCount', 'TotalAmount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62080e00-6344-4942-957b-d333b1af967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 5: DATA QUALITY & FRAUD ANALYSIS ===\n",
      "1. Missing values check:\n",
      "TransactionId             0\n",
      "BatchId                   0\n",
      "AccountId                 0\n",
      "SubscriptionId            0\n",
      "CustomerId                0\n",
      "CurrencyCode              0\n",
      "CountryCode               0\n",
      "ProviderId                0\n",
      "ProductId                 0\n",
      "ProductCategory           0\n",
      "ChannelId                 0\n",
      "Amount                    0\n",
      "Value                     0\n",
      "TransactionStartTime      0\n",
      "PricingStrategy           0\n",
      "FraudResult               0\n",
      "TransactionId_numeric     0\n",
      "BatchId_numeric           0\n",
      "AccountId_numeric         0\n",
      "SubscriptionId_numeric    0\n",
      "CustomerId_numeric        0\n",
      "ProviderId_numeric        0\n",
      "ProductId_numeric         0\n",
      "ChannelId_numeric         0\n",
      "TransactionHour           0\n",
      "TransactionDay            0\n",
      "TransactionMonth          0\n",
      "TransactionYear           0\n",
      "dtype: int64\n",
      "\n",
      "2. Fraud analysis:\n",
      "             Count   AvgAmount  TotalAmount\n",
      "FraudResult                                \n",
      "0            95469     3627.72  346335054.5\n",
      "1              193  1535272.39  296307571.0\n",
      "\n",
      "Fraud rate: 0.20%\n",
      "\n",
      "3. Fraud by product category:\n",
      "                    count  sum      mean  fraud_rate\n",
      "ProductCategory                                     \n",
      "transport              25    2  0.080000        8.00\n",
      "utility_bill         1920   12  0.006250        0.62\n",
      "financial_services  45405  161  0.003546        0.35\n",
      "airtime             45027   18  0.000400        0.04\n",
      "data_bundles         1613    0  0.000000        0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 5: DATA QUALITY & FRAUD ANALYSIS ===\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"1. Missing values check:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Analyze fraud cases\n",
    "print(\"\\n2. Fraud analysis:\")\n",
    "fraud_summary = df.groupby('FraudResult').agg({\n",
    "    'TransactionId': 'count',\n",
    "    'Amount': ['mean', 'sum']\n",
    "}).round(2)\n",
    "\n",
    "fraud_summary.columns = ['Count', 'AvgAmount', 'TotalAmount']\n",
    "print(fraud_summary)\n",
    "\n",
    "# Fraud rate\n",
    "fraud_rate = (df['FraudResult'].sum() / len(df)) * 100\n",
    "print(f\"\\nFraud rate: {fraud_rate:.2f}%\")\n",
    "\n",
    "print(\"\\n3. Fraud by product category:\")\n",
    "fraud_by_product = df.groupby('ProductCategory')['FraudResult'].agg(['count', 'sum', 'mean'])\n",
    "fraud_by_product['fraud_rate'] = (fraud_by_product['sum'] / fraud_by_product['count'] * 100).round(2)\n",
    "print(fraud_by_product.sort_values('fraud_rate', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd7f314d-d555-4f30-83f9-0d737e1c7fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TASK 2: EDA KEY INSIGHTS ===\n",
      "\n",
      "1. DATA OVERVIEW:\n",
      "   • 95,662 transactions, 28 columns (16 original + engineered)\n",
      "   • Time period: 2018-11-15 to 2019-02-13\n",
      "   • 3,633 unique customers identified\n",
      "   • 0 missing values - data quality is excellent\n",
      "\n",
      "2. FRAUD ANALYSIS:\n",
      "   • Very low fraud rate: 0.20% (193 fraud cases)\n",
      "   • Fraud transactions are HUGE: avg $1,535,272.39 vs normal $3,627.72\n",
      "   • 'transport' category has highest fraud rate (8%), but small sample (25 transactions)\n",
      "\n",
      "3. TEMPORAL PATTERNS:\n",
      "   • Peak transaction hours: 7-9 AM (local time)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fraud_by_month' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m3. TEMPORAL PATTERNS:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   • Peak transaction hours: 7-9 AM (local time)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   • December and January are busiest months (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfraud_by_month\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m12\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfraud_by_month\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m transactions)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   • Data covers ~3 months: Nov 2018 - Feb 2019\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m4. CUSTOMER BEHAVIOR:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fraud_by_month' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=== TASK 2: EDA KEY INSIGHTS ===\")\n",
    "print(\"\\n1. DATA OVERVIEW:\")\n",
    "print(f\"   • {df.shape[0]:,} transactions, {df.shape[1]} columns (16 original + engineered)\")\n",
    "print(f\"   • Time period: {df['TransactionStartTime'].min().date()} to {df['TransactionStartTime'].max().date()}\")\n",
    "print(f\"   • {customer_stats.shape[0]:,} unique customers identified\")\n",
    "print(f\"   • 0 missing values - data quality is excellent\")\n",
    "\n",
    "print(\"\\n2. FRAUD ANALYSIS:\")\n",
    "print(f\"   • Very low fraud rate: 0.20% ({df['FraudResult'].sum()} fraud cases)\")\n",
    "print(f\"   • Fraud transactions are HUGE: avg ${fraud_summary.loc[1, 'AvgAmount']:,.2f} vs normal ${fraud_summary.loc[0, 'AvgAmount']:,.2f}\")\n",
    "print(f\"   • 'transport' category has highest fraud rate (8%), but small sample (25 transactions)\")\n",
    "\n",
    "print(\"\\n3. TEMPORAL PATTERNS:\")\n",
    "print(f\"   • Peak transaction hours: 7-9 AM (local time)\")\n",
    "print(f\"   • December and January are busiest months ({fraud_by_month.loc[12, 'count']:,} and {fraud_by_month.loc[1, 'count']:,} transactions)\")\n",
    "print(f\"   • Data covers ~3 months: Nov 2018 - Feb 2019\")\n",
    "\n",
    "print(\"\\n4. CUSTOMER BEHAVIOR:\")\n",
    "print(f\"   • Transaction distribution is highly skewed\")\n",
    "print(f\"   • Most customers make few transactions, few customers are very active\")\n",
    "print(f\"   • Currency: 100% UGX (Ugandan Shilling)\")\n",
    "print(f\"   • Country: 100% Uganda (code 256)\")\n",
    "\n",
    "print(\"\\n5. RECOMMENDATIONS FOR TASK 3:\")\n",
    "print(\"   • Use RFM metrics for proxy target (Task 4)\")\n",
    "print(\"   • Focus on: transaction frequency, monetary value, recency\")\n",
    "print(\"   • Consider fraud as separate model or feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b116e25-bf87-4d9f-8275-ae0728198a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FIX MISSING VARIABLE ===\n",
      "Transactions by month with fraud:\n",
      "                  count  fraud_count  fraud_rate\n",
      "TransactionMonth                                \n",
      "1                 31783           64        0.20\n",
      "2                 15772           53        0.34\n",
      "11                12472           14        0.11\n",
      "12                35635           62        0.17\n",
      "\n",
      "Busiest month: Month 12 with 35,635 transactions\n"
     ]
    }
   ],
   "source": [
    "print(\"=== FIX MISSING VARIABLE ===\")\n",
    "\n",
    "# Create fraud_by_month analysis\n",
    "fraud_by_month = df.groupby('TransactionMonth').agg({\n",
    "    'TransactionId': 'count',\n",
    "    'FraudResult': 'sum'\n",
    "})\n",
    "fraud_by_month.columns = ['count', 'fraud_count']\n",
    "fraud_by_month['fraud_rate'] = (fraud_by_month['fraud_count'] / fraud_by_month['count'] * 100).round(2)\n",
    "\n",
    "print(\"Transactions by month with fraud:\")\n",
    "print(fraud_by_month)\n",
    "\n",
    "print(f\"\\nBusiest month: Month {fraud_by_month['count'].idxmax()} with {fraud_by_month['count'].max():,} transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b84fa4-edc3-4a72-b52f-05b6de5f8e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TASK 2 COMPLETE: FINAL INSIGHTS ===\n",
      "\n",
      "1. DATA OVERVIEW:\n",
      "   • 95,662 transactions, 28 columns\n",
      "   • 3,633 unique customers\n",
      "   • Time: Nov 2018 - Feb 2019 (3 months)\n",
      "   • 0 missing values\n",
      "\n",
      "2. FRAUD & RISK PATTERNS:\n",
      "   • Fraud rate: 0.20% (193 cases)\n",
      "   • Fraud avg: $1.53M vs Normal: $3,627\n",
      "   • Month 2 has highest fraud rate (0.34%)\n",
      "\n",
      "3. BUSINESS IMPLICATIONS:\n",
      "   • Customers highly varied: few active, many inactive\n",
      "   • RFM analysis needed for credit risk proxy\n",
      "   • Fraud too rare for prediction - use as feature only\n",
      "\n",
      "✅ TASK 2 COMPLETE - Ready for Feature Engineering\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TASK 2 COMPLETE: FINAL INSIGHTS ===\")\n",
    "\n",
    "print(\"\\n1. DATA OVERVIEW:\")\n",
    "print(f\"   • 95,662 transactions, 28 columns\")\n",
    "print(f\"   • 3,633 unique customers\")\n",
    "print(f\"   • Time: Nov 2018 - Feb 2019 (3 months)\")\n",
    "print(f\"   • 0 missing values\")\n",
    "\n",
    "print(\"\\n2. FRAUD & RISK PATTERNS:\")\n",
    "print(f\"   • Fraud rate: 0.20% (193 cases)\")\n",
    "print(f\"   • Fraud avg: $1.53M vs Normal: $3,627\")\n",
    "print(f\"   • Month 2 has highest fraud rate (0.34%)\")\n",
    "\n",
    "print(\"\\n3. BUSINESS IMPLICATIONS:\")\n",
    "print(f\"   • Customers highly varied: few active, many inactive\")\n",
    "print(f\"   • RFM analysis needed for credit risk proxy\")\n",
    "print(f\"   • Fraud too rare for prediction - use as feature only\")\n",
    "\n",
    "print(\"\\n✅ TASK 2 COMPLETE - Ready for Feature Engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebf901c7-6bd2-4d23-b191-418f0c6db12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature engineering script created\n",
      "Next: Add more feature transformations\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Task 3: Feature Engineering\n",
    "Process raw data into model-ready features with RFM metrics\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RFMFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Calculate RFM (Recency, Frequency, Monetary) features\"\"\"\n",
    "    \n",
    "    def __init__(self, snapshot_date='2019-02-28'):\n",
    "        self.snapshot_date = pd.to_datetime(snapshot_date)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Convert to datetime\n",
    "        X['TransactionStartTime'] = pd.to_datetime(X['TransactionStartTime'])\n",
    "        \n",
    "        # Customer-level RFM calculations\n",
    "        customer_rfm = X.groupby('AccountId_numeric').agg({\n",
    "            'TransactionStartTime': lambda x: (self.snapshot_date - x.max()).days,\n",
    "            'TransactionId': 'count',\n",
    "            'Amount': ['sum', 'mean', 'std']\n",
    "        })\n",
    "        \n",
    "        customer_rfm.columns = ['Recency', 'Frequency', 'Monetary_Total', \n",
    "                                'Monetary_Avg', 'Monetary_Std']\n",
    "        \n",
    "        # Merge back to original data\n",
    "        X = X.merge(customer_rfm, left_on='AccountId_numeric', \n",
    "                    right_index=True, how='left')\n",
    "        \n",
    "        return X\n",
    "\n",
    "print(\"✅ Feature engineering script created\")\n",
    "print(\"Next: Add more feature transformations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0512783f-61ab-49a1-ab7b-d3496d6fb5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing feature engineering...\n",
      "Loading data from: ../data/raw/data.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 92\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting feature engineering...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Load sample data\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m df \u001b[38;5;241m=\u001b[39m process_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/raw/data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Apply RFM features\u001b[39;00m\n\u001b[0;32m     95\u001b[0m rfm_engineer \u001b[38;5;241m=\u001b[39m RFMFeatureEngineer()\n",
      "Cell \u001b[1;32mIn[13], line 75\u001b[0m, in \u001b[0;36mprocess_data\u001b[1;34m(raw_data_path)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load and process raw data\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_data_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(raw_data_path)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Extract numeric IDs\u001b[39;00m\n\u001b[0;32m     78\u001b[0m id_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatchId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccountId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubscriptionId\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     79\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProviderId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProductId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChannelId\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/raw/data.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Task 3: Feature Engineering\n",
    "Process raw data into model-ready features with RFM metrics\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RFMFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Calculate RFM (Recency, Frequency, Monetary) features\"\"\"\n",
    "    \n",
    "    def __init__(self, snapshot_date='2019-02-28'):\n",
    "        self.snapshot_date = pd.to_datetime(snapshot_date)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Convert to datetime\n",
    "        X['TransactionStartTime'] = pd.to_datetime(X['TransactionStartTime'])\n",
    "        \n",
    "        # Customer-level RFM calculations (FIXED: x.max() not X.max())\n",
    "        customer_rfm = X.groupby('AccountId_numeric').agg({\n",
    "            'TransactionStartTime': lambda x: (self.snapshot_date - x.max()).days,\n",
    "            'TransactionId': 'count',\n",
    "            'Amount': ['sum', 'mean', 'std']\n",
    "        })\n",
    "        \n",
    "        customer_rfm.columns = ['Recency', 'Frequency', 'Monetary_Total', \n",
    "                                'Monetary_Avg', 'Monetary_Std']\n",
    "        \n",
    "        # Merge back to original data\n",
    "        X = X.merge(customer_rfm, left_on='AccountId_numeric', \n",
    "                    right_index=True, how='left')\n",
    "        \n",
    "        return X\n",
    "\n",
    "class AdditionalFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Create additional features for credit risk prediction\"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # 1. Transaction time features\n",
    "        X['TransactionHour'] = X['TransactionStartTime'].dt.hour\n",
    "        X['TransactionDay'] = X['TransactionStartTime'].dt.day\n",
    "        X['TransactionMonth'] = X['TransactionStartTime'].dt.month\n",
    "        X['TransactionDayOfWeek'] = X['TransactionStartTime'].dt.dayofweek\n",
    "        \n",
    "        # 2. Behavioral features\n",
    "        X['Amount_to_Value_Ratio'] = X['Amount'] / (X['Value'] + 1)  # Avoid division by zero\n",
    "        X['Is_Refund'] = (X['Amount'] < 0).astype(int)\n",
    "        \n",
    "        # 3. Customer engagement features\n",
    "        X['Customer_Tenure_Days'] = (X['TransactionStartTime'].max() - \n",
    "                                    X.groupby('AccountId_numeric')['TransactionStartTime'].transform('min')).dt.days\n",
    "        \n",
    "        return X\n",
    "\n",
    "# Main processing function\n",
    "def process_data(raw_data_path):\n",
    "    \"\"\"Load and process raw data\"\"\"\n",
    "    print(f\"Loading data from: {raw_data_path}\")\n",
    "    df = pd.read_csv(raw_data_path)\n",
    "    \n",
    "    # Extract numeric IDs\n",
    "    id_columns = ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', \n",
    "                  'CustomerId', 'ProviderId', 'ProductId', 'ChannelId']\n",
    "    \n",
    "    for col in id_columns:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_numeric'] = df[col].str.extract(r'(\\d+)$').astype(float)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the feature engineering\n",
    "    print(\"Testing feature engineering...\")\n",
    "    \n",
    "    # Load sample data\n",
    "    df = process_data(\"../data/raw/data.csv\")\n",
    "    \n",
    "    # Apply RFM features\n",
    "    rfm_engineer = RFMFeatureEngineer()\n",
    "    df_with_rfm = rfm_engineer.fit_transform(df)\n",
    "    \n",
    "    # Apply additional features\n",
    "    additional_engineer = AdditionalFeatureEngineer()\n",
    "    df_with_features = additional_engineer.fit_transform(df_with_rfm)\n",
    "    \n",
    "    print(f\"✓ Original columns: {len(df.columns)}\")\n",
    "    print(f\"✓ After feature engineering: {len(df_with_features.columns)}\")\n",
    "    print(f\"✓ New features added: {list(df_with_features.columns[-10:])}\")\n",
    "    print(f\"\\nSample of new RFM features:\")\n",
    "    print(df_with_features[['AccountId_numeric', 'Recency', 'Frequency', 'Monetary_Total']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a426ee4c-19a9-41b6-8c9b-6ba43ded8cd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3967668709.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python src/data_processing.p\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python src/data_processing.p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6940dfbe-3688-4d4c-8a91-333b12ca01f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
